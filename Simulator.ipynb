{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trace\n",
    "    def __init__(self):\n",
    "        self.jobs_list = []\n",
    "    def read_trace(self, data_file):\n",
    "        '''Reads in the trace and outputs a list of jobs'''\n",
    "        pass \n",
    "        return self.jobs_list\n",
    "    def __len__(self):\n",
    "        return len(self.jobs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPU\n",
    "    def __init__:\n",
    "        self.id = None\n",
    "        self.state = 'available'\n",
    "        ### do we need a self.job_id for the job it's currently running? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self):\n",
    "        self.n_gpu = None\n",
    "        self.gpus = []\n",
    "        self.gpus_available = []\n",
    "    def get_gpus(self):\n",
    "        '''Returns a list of available gpus'''\n",
    "        for g in range(len(self.gpus)):\n",
    "            if g.state == 'available':\n",
    "                self.gpus_available.append(g)\n",
    "        return gpus_available\n",
    "    def __len__(self):\n",
    "        return len(self.gpus_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self):\n",
    "        self.arrival_time = None\n",
    "        self.id = None\n",
    "        self.arrival_time = None\n",
    "        self.start_time =None\n",
    "        self.end_time = None\n",
    "        self.real_duration = None\n",
    "        self.predicted_duration = None\n",
    "    def get_predicted_duration:\n",
    "        '''Gets a predicted duration for the job based on our ML algorithm'''\n",
    "        pass\n",
    "    def get_actual_duration:\n",
    "        '''Gets the actual job duration from the trace'''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_queue(trace, job, queue):\n",
    "    if len(cluster) = 0:\n",
    "        queue.append(job)\n",
    "\n",
    "def scheduler(job, trace, queue, gpu):\n",
    "    jobs_to_schedule = []\n",
    "    while len(trace) > 0 or len(queue) > 0\n",
    "        jobs_to_schedule = trace.jobs_list + queue\n",
    "        jobs_to_schedule.sort(key=lambda x: x.predicted_duration, reverse=True)\n",
    "        if len(cluster) > 0:\n",
    "            break\n",
    "    ### here do we just take the longest/shortest job and assign it to a gpu? \n",
    "    \n",
    "    gpu.state = 'allocated'\n",
    "    #update job.start_time and job.end_time = job.arrival_time+job.start_time+job_duration\n",
    "    #note the time in the csv that the job is assigned to the gpu\n",
    "    counter++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    queue = []\n",
    "    global counter = 0\n",
    "    data_file = ''\n",
    "    t = Trace()\n",
    "    t.read_trace(data_file)\n",
    "    ### how do we create gpu and cluster objects? is this done once at the beginning?\n",
    "    g = GPU()\n",
    "    c = Cluster()\n",
    "    ### the code below will depend on the question about the scheduler\n",
    "    for u in range(len(t)):\n",
    "        j = Job()\n",
    "        scheduler(j, t, queue, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
